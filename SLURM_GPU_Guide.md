# SLURM GPU ì‘ì—… ì„¤ì • ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [SLURM ê¸°ë³¸ ì‚¬ìš©ë²•](#slurm-ê¸°ë³¸-ì‚¬ìš©ë²•)
2. [ê·¸ë˜í”½ì¹´ë“œë³„ ìµœì  ì„¤ì •](#ê·¸ë˜í”½ì¹´ë“œë³„-ìµœì -ì„¤ì •)
3. [ì‘ì—… ì œì¶œ ë° ê´€ë¦¬](#ì‘ì—…-ì œì¶œ-ë°-ê´€ë¦¬)
4. [ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…](#ëª¨ë‹ˆí„°ë§-ë°-ë””ë²„ê¹…)
5. [ì‹¤ì „ ì˜ˆì‹œ](#ì‹¤ì „-ì˜ˆì‹œ)

---

## ğŸš€ SLURM ê¸°ë³¸ ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‘ì—… ì œì¶œ
```bash
# ê¸°ë³¸ ì œì¶œ
sbatch ìŠ¤í¬ë¦½íŠ¸íŒŒì¼.slurm

# ì˜µì…˜ê³¼ í•¨ê»˜ ì œì¶œ
sbatch --job-name=ì‘ì—…ì´ë¦„ --partition=íŒŒí‹°ì…˜ëª… ìŠ¤í¬ë¦½íŠ¸íŒŒì¼.slurm
```

### ì£¼ìš” SLURM ì˜µì…˜ë“¤
```bash
# ì‘ì—… ì´ë¦„
--job-name=gr00t_training

# íŒŒí‹°ì…˜ ì„ íƒ
--partition=markov_gpu

# GPU ì„¤ì •
--gres=gpu:4                    # GPU 4ê°œ ì‚¬ìš©
--constraint=gpu4090            # RTX 4090 íƒ€ì… ì§€ì •
--constraint=gpul40s            # L40S íƒ€ì… ì§€ì •

# ë…¸ë“œ ì„¤ì •
--nodelist=classt25             # íŠ¹ì • ë…¸ë“œ ì§€ì •
--nodes=1                       # ë…¸ë“œ ìˆ˜
--ntasks=1                      # íƒœìŠ¤í¬ ìˆ˜

# ë¦¬ì†ŒìŠ¤ ì„¤ì •
--cpus-per-task=32              # CPU ì½”ì–´ ìˆ˜
--mem=200G                      # ë©”ëª¨ë¦¬ ìš©ëŸ‰
--time=24:00:00                 # ì‹¤í–‰ ì‹œê°„ ì œí•œ

# ì¶œë ¥ ì„¤ì •
--output=logs/job_%j.out        # í‘œì¤€ ì¶œë ¥ íŒŒì¼
--error=logs/job_%j.err         # ì—ëŸ¬ ì¶œë ¥ íŒŒì¼
```

---

## ğŸ¯ ê·¸ë˜í”½ì¹´ë“œë³„ ìµœì  ì„¤ì •

### RTX 4090 (24GB VRAM)
```bash
# ê¸°ë³¸ ì„¤ì •
--gres=gpu:4
--constraint=gpu4090
--cpus-per-task=32
--mem=200G
--time=24:00:00

# í•™ìŠµ ì„¤ì •
--batch-size=24
--gradient-accumulation-steps=1
# ì´ effective batch size: 24 Ã— 4 Ã— 1 = 96

# ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 18-20GB per GPU (75-80% í™œìš©ë„)
```

### L40S (48GB VRAM)
```bash
# ê¸°ë³¸ ì„¤ì •
--gres=gpu:4
--constraint=gpul40s
--cpus-per-task=48
--mem=300G
--time=24:00:00

# í•™ìŠµ ì„¤ì •
--batch-size=32
--gradient-accumulation-steps=1
# ì´ effective batch size: 32 Ã— 4 Ã— 1 = 128

# ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 25-30GB per GPU (50-60% í™œìš©ë„)
```

### A100 (80GB VRAM)
```bash
# ê¸°ë³¸ ì„¤ì •
--gres=gpu:4
--constraint=gpuA100
--cpus-per-task=64
--mem=500G
--time=24:00:00

# í•™ìŠµ ì„¤ì •
--batch-size=48
--gradient-accumulation-steps=1
# ì´ effective batch size: 48 Ã— 4 Ã— 1 = 192

# ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 35-40GB per GPU (45-50% í™œìš©ë„)
```

---

## ğŸ“Š ë¦¬ì†ŒìŠ¤ ì„¤ì • ê¸°ì¤€

### CPU ì„¤ì • ê¸°ì¤€
| GPU ê°œìˆ˜ | ê¶Œì¥ CPU | ì´ìœ  |
|----------|----------|------|
| 1ê°œ | 8-16ê°œ | ë°ì´í„° ë¡œë”©, ì „ì²˜ë¦¬ |
| 2ê°œ | 16-32ê°œ | GPU ê°„ í†µì‹  ì˜¤ë²„í—¤ë“œ |
| 4ê°œ | 32-64ê°œ | NCCL í†µì‹ , ë³‘ë ¬ ì²˜ë¦¬ |
| 8ê°œ+ | 64-128ê°œ | ëŒ€ê·œëª¨ ë³‘ë ¬ ì²˜ë¦¬ |

### ë©”ëª¨ë¦¬ ì„¤ì • ê¸°ì¤€
| GPU íƒ€ì… | GPU ë©”ëª¨ë¦¬ | ê¶Œì¥ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ | ë¹„ìœ¨ |
|----------|------------|-------------------|------|
| RTX 4090 | 24GB | 200-300GB | 4-6ë°° |
| L40S | 48GB | 300-500GB | 4-6ë°° |
| A100 | 80GB | 500GB+ | 4-6ë°° |

---

## ğŸ”§ ì‘ì—… ì œì¶œ ë° ê´€ë¦¬

### ì‘ì—… ì œì¶œ
```bash
# RTX 4090 ë…¸ë“œì— ì‘ì—… ì œì¶œ
sbatch \
  --job-name=gr00t_rtx4090 \
  --partition=markov_gpu \
  --gres=gpu:4 \
  --constraint=gpu4090 \
  --nodelist=classt25 \
  --cpus-per-task=32 \
  --mem=200G \
  --time=24:00:00 \
  finetune_RTX4090.slurm

# L40S ë…¸ë“œì— ì‘ì—… ì œì¶œ
sbatch \
  --job-name=gr00t_l40s \
  --partition=markov_gpu \
  --gres=gpu:4 \
  --constraint=gpul40s \
  --nodelist=classt22 \
  --cpus-per-task=48 \
  --mem=300G \
  --time=24:00:00 \
  finetune_L40S.slurm
```

### ì‘ì—… ìƒíƒœ í™•ì¸
```bash
# ë‚´ ì‘ì—… ëª©ë¡
squeue -u $USER

# íŠ¹ì • ì‘ì—… ìƒì„¸ ì •ë³´
scontrol show job JOBID

# ë…¸ë“œ ìƒíƒœ í™•ì¸
sinfo -N
sinfo -p markov_gpu
```

### ì‘ì—… ì œì–´
```bash
# ì‘ì—… ì·¨ì†Œ
scancel JOBID

# ì‘ì—… ì¼ì‹œì •ì§€
scontrol suspend JOBID

# ì‘ì—… ì¬ê°œ
scontrol resume JOBID

# ëª¨ë“  ì‘ì—… ì·¨ì†Œ
scancel -u $USER
```

---

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…

### ë¡œê·¸ í™•ì¸
```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§
tail -f logs/finetune_JOBID.out
tail -f logs/finetune_JOBID.err

# ë¡œê·¸ ê²€ìƒ‰
grep "error\|Error\|ERROR" logs/finetune_JOBID.err
grep "loss\|grad_norm" logs/finetune_JOBID.out
```

### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
```bash
# GPU ì‚¬ìš©ëŸ‰ í™•ì¸
srun -p markov_gpu -w ë…¸ë“œëª… nvidia-smi

# CPU ì‚¬ìš©ë¥  í™•ì¸
srun -p markov_gpu -w ë…¸ë“œëª… top -n 1

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
srun -p markov_gpu -w ë…¸ë“œëª… free -h
```

### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
```bash
# ì‘ì—… ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ í™•ì¸
watch -n 5 'squeue -u $USER'

# ë…¸ë“œ ìƒíƒœ ì‹¤ì‹œê°„ í™•ì¸
watch -n 10 'sinfo -N'
```

---

## ğŸ¯ ì‹¤ì „ ì˜ˆì‹œ

### í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë…¸ë“œ í™•ì¸
```bash
# GPU ë…¸ë“œ ìƒíƒœ í™•ì¸
sinfo -N -o "%N %P %T %G" | grep "gpu:" | grep -E "idle|mixed"

# íŠ¹ì • GPU íƒ€ì… ë…¸ë“œ í™•ì¸
sinfo -N -o "%N %P %T %G" | grep "gpu:" | grep -E "idle|mixed" | grep -E "gpu:4|gpu:14"
```

### í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •ê°’ ì „ë‹¬
```bash
# ì œì¶œ ì‹œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
sbatch --export=BATCH_SIZE=24,ACCUM_STEPS=1,GPU_TYPE=rtx4090 finetune_RTX4090.slurm

# ìŠ¤í¬ë¦½íŠ¸ì—ì„œ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
python scripts/gr00t_finetune.py \
  --batch-size ${BATCH_SIZE:-24} \
  --gradient-accumulation-steps ${ACCUM_STEPS:-1} \
  --gpu-type ${GPU_TYPE:-rtx4090}
```

### ìŠ¤í¬ë¦½íŠ¸ í…œí”Œë¦¿
```bash
#!/bin/bash
#SBATCH --job-name=gr00t_training
#SBATCH --partition=markov_gpu
#SBATCH --gres=gpu:4
#SBATCH --constraint=gpu4090
#SBATCH --cpus-per-task=32
#SBATCH --mem=200G
#SBATCH --time=24:00:00
#SBATCH --output=logs/finetune_%j.out
#SBATCH --error=logs/finetune_%j.err

# í™˜ê²½ ì„¤ì •
export CUDA_VISIBLE_DEVICES=0,1,2,3
export OMP_NUM_THREADS=8
export NCCL_DEBUG=INFO
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:2048

# í•™ìŠµ ì‹¤í–‰
python scripts/gr00t_finetune.py \
  --dataset-path ./demo_data/ \
  --num-gpus 4 \
  --output-dir ./checkpoints \
  --max-steps 10000 \
  --batch-size 24 \
  --gradient-accumulation-steps 1 \
  --save-steps 1000
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### GPU ì†ì‹¤ ë°©ì§€
- **ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ë„ˆë¬´ í¬ê²Œ ì„¤ì •í•˜ì§€ ë§ ê²ƒ**
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ëª¨ë‹ˆí„°ë§í•  ê²ƒ**
- **ì˜¨ë„ì™€ ì „ë ¥ ê³µê¸‰ì„ í™•ì¸í•  ê²ƒ**

### ë¦¬ì†ŒìŠ¤ ìµœì í™”
- **CPUê°€ ë¶€ì¡±í•˜ë©´**: ë°ì´í„° ë¡œë”©ì´ ëŠë ¤ì§
- **ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ë©´**: OOM ì—ëŸ¬ ë°œìƒ
- **ë¦¬ì†ŒìŠ¤ê°€ ë‚¨ìœ¼ë©´**: ë¹„ìš© ë‚­ë¹„

### ì•ˆì „í•œ ì„¤ì • ê¶Œì¥
- **ë³´ìˆ˜ì  ì„¤ì •ìœ¼ë¡œ ì‹œì‘**
- **ì ì§„ì ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ ì¦ê°€**
- **ëª¨ë‹ˆí„°ë§ì„ í†µí•œ ìµœì í™”**

---

## ğŸ“š ìœ ìš©í•œ ëª…ë ¹ì–´ ëª¨ìŒ

```bash
# ì‘ì—… ê´€ë ¨
squeue -u $USER                    # ë‚´ ì‘ì—… ëª©ë¡
scancel JOBID                      # ì‘ì—… ì·¨ì†Œ
scontrol show job JOBID            # ì‘ì—… ìƒì„¸ ì •ë³´

# ë…¸ë“œ ê´€ë ¨
sinfo -N                           # ëª¨ë“  ë…¸ë“œ ìƒíƒœ
sinfo -p markov_gpu                # GPU íŒŒí‹°ì…˜ ìƒíƒœ
sinfo -N -o "%N %P %T %G"          # ë…¸ë“œë³„ GPU ì •ë³´

# ëª¨ë‹ˆí„°ë§
watch -n 5 'squeue -u $USER'       # ì‹¤ì‹œê°„ ì‘ì—… ëª¨ë‹ˆí„°ë§
tail -f logs/finetune_JOBID.out    # ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸
```

---

*ì´ ê°€ì´ë“œëŠ” GR00T ëª¨ë¸ íŒŒì¸íŠœë‹ì„ ìœ„í•œ SLURM ì„¤ì •ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ ì¡°ì •í•˜ì„¸ìš”.*
