# ğŸš€ Isaac-GR00T ìµœì¢… í•™ìŠµ ì „ëµ

## ğŸ“Š ì‹¤ì œ GPU êµ¬ì„± (ì •í™•í•œ ì¡°ì‚¬ ê²°ê³¼)

### **ì‚¬ìš© ê°€ëŠ¥í•œ GPU ë…¸ë“œ**

| ë…¸ë“œ | GPU íƒ€ì… | GPU ê°œìˆ˜ | GPU ë©”ëª¨ë¦¬ | CPU | RAM | Feature | ìƒíƒœ |
|------|----------|----------|------------|-----|-----|---------|------|
| **classt21** | L40S | 4 | 48GB | 96 | 257GB | `gpul40s` | âœ… IDLE |
| **classt22** | L40S | 4 | 48GB | 96 | 257GB | `gpul40s` | âœ… IDLE |
| **classt25** | RTX 4090 | 4 | 24GB | 64 | 386GB | `gpu4090` | âœ… IDLE |
| **classt23** | H100 NVL | 2 (14 MIG) | 94GB | 48 | 514GB | `gpu2h100` | âœ… IDLE |
| **classt24** | H100 NVL | 2 (14 MIG) | 94GB | 24 | 514GB | `gpu2h100` | âœ… IDLE |
| classt01-18 | RTX 2080 Ti | 2 | 11GB | 20 | 128GB | `gpu2080` | âœ… ë§ìŒ |

### **í•µì‹¬ ë°œê²¬ì‚¬í•­**

1. **GPU íƒ€ì… ì§€ì • ë°©ë²•**:
   - âŒ ì˜ëª»: `--gres=gpu:gpul40s:4`
   - âœ… ì˜¬ë°”ë¦„: `--gres=gpu:4 --constraint=gpul40s`
   - âœ… ë˜ëŠ”: `--gres=gpu:4 -C gpul40s`

2. **ì‹¤ì œ GPU ê°œìˆ˜**:
   - L40S: ë…¸ë“œë‹¹ **4ê°œ** (6ê°œ ì•„ë‹˜!)
   - RTX 4090: ë…¸ë“œë‹¹ **4ê°œ**
   - H100: ë¬¼ë¦¬ì  2ê°œ, MIGë¡œ 14ê°œ ì¸ìŠ¤í„´ìŠ¤

---

## ğŸ¯ ìµœì  ì „ëµ (ì„±ëŠ¥ ìˆœìœ„)

### **ğŸ¥‡ ì „ëµ 1: L40S (ìµœê³  ì„±ëŠ¥ + ë©”ëª¨ë¦¬)**

```bash
ë…¸ë“œ: classt21 ë˜ëŠ” classt22
GPU: L40S Ã— 4 (48GB each = 192GB total)
ì„±ëŠ¥: 183 TFLOPS (FP16) Ã— 4 = 732 TFLOPS
```

**SLURM ì„¤ì •:**
```bash
#SBATCH --gres=gpu:4
#SBATCH --constraint=gpul40s
#SBATCH --cpus-per-task=32
#SBATCH --mem=200G
```

**í•™ìŠµ ì„¤ì •:**
```bash
--batch-size 16        # L40S 48GB ìµœëŒ€ í™œìš©
--gradient-accumulation-steps 2
# Effective: 16 Ã— 4 Ã— 2 = 128
```

**ì˜ˆìƒ ì‹œê°„**: 10,000 steps â‰ˆ **7-9ì‹œê°„**

---

### **ğŸ¥ˆ ì „ëµ 2: RTX 4090 (ê· í˜•)**

```bash
ë…¸ë“œ: classt25
GPU: RTX 4090 Ã— 4 (24GB each = 96GB total)
ì„±ëŠ¥: 165 TFLOPS (FP16) Ã— 4 = 660 TFLOPS
```

**SLURM ì„¤ì •:**
```bash
#SBATCH --gres=gpu:4
#SBATCH --constraint=gpu4090
#SBATCH --cpus-per-task=32
#SBATCH --mem=200G
```

**í•™ìŠµ ì„¤ì •:**
```bash
--batch-size 10
--gradient-accumulation-steps 3
# Effective: 10 Ã— 4 Ã— 3 = 120
```

**ì˜ˆìƒ ì‹œê°„**: 10,000 steps â‰ˆ **10-12ì‹œê°„**

---

### **ğŸ¥‰ ì „ëµ 3: RTX 2080 Ti (í•­ìƒ ì‚¬ìš© ê°€ëŠ¥)**

```bash
ë…¸ë“œ: classt01-18 (ë§ìŒ)
GPU: RTX 2080 Ti Ã— 2 (11GB each = 22GB total)
ì„±ëŠ¥: 27 TFLOPS (FP16) Ã— 2 = 54 TFLOPS
```

**SLURM ì„¤ì •:**
```bash
#SBATCH --gres=gpu:2
#SBATCH --constraint=gpu2080
#SBATCH --cpus-per-task=16
#SBATCH --mem=100G
```

**í•™ìŠµ ì„¤ì •:**
```bash
--batch-size 4
--gradient-accumulation-steps 10
# Effective: 4 Ã— 2 Ã— 10 = 80
```

**ì˜ˆìƒ ì‹œê°„**: 10,000 steps â‰ˆ **18-24ì‹œê°„**

---

## ğŸ’¡ ìµœì¢… ê¶Œì¥ ì‚¬í•­

### **ì¦‰ì‹œ ì‹œì‘í•˜ë ¤ë©´: L40S (ì¶”ì²œ!)**

L40Sê°€ **IDLE ìƒíƒœ**ì´ê³  **48GB ë©”ëª¨ë¦¬**ë¡œ ê°€ì¥ í° batch size ì‚¬ìš© ê°€ëŠ¥!

```bash
sbatch finetune_gr00t_L40S.slurm
```

### **ëŒ€ê¸° ì‹œê°„ ìµœì†Œí™”: 4090**

4090ë„ IDLEì´ê³  ì¶©ë¶„íˆ ë¹ ë¦„:

```bash
sbatch finetune_gr00t_4090.slurm
```

---

## ğŸ“‹ ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì • ì‚¬í•­

### **ì¤‘ìš”í•œ ìˆ˜ì •**

1. **GPU íƒ€ì… ì§€ì • ë°©ì‹** (Feature ì‚¬ìš©):
   ```bash
   # ì˜ëª»ëœ ë°©ì‹
   #SBATCH --gres=gpu:gpul40s:4  âŒ
   
   # ì˜¬ë°”ë¥¸ ë°©ì‹
   #SBATCH --gres=gpu:4
   #SBATCH --constraint=gpul40s  âœ…
   ```

2. **huggingface_hub ì„¤ì¹˜ ìˆœì„œ**:
   ```bash
   # ëª¨ë“ˆ ë¡œë“œ â†’ venv ìƒì„± â†’ hf CLI ì„¤ì¹˜ â†’ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
   module load Python/3.10.8-GCCcore-12.2.0 CUDA/12.6.0
   python -m venv venv
   source venv/bin/activate
   pip install "huggingface_hub[cli]"  # ë¨¼ì €!
   hf download ...  # ê·¸ ë‹¤ìŒ
   ```

3. **gr00t íŒ¨í‚¤ì§€ ì„¤ì¹˜**:
   ```bash
   # ë°ì´í„° ë‹¤ìš´ë¡œë“œ í›„
   pip install -e .[base]
   ```

---

## âš¡ ìµœì í™”ëœ ìŠ¤í¬ë¦½íŠ¸ í…œí”Œë¦¿

ì™„ì „íˆ ì‘ë™í•˜ëŠ” ìµœì¢… ë²„ì „ì„ ì œê³µí•©ë‹ˆë‹¤!

